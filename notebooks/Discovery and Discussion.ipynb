{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinyin Spelling Corrector (inspired by Peter Norvig) and Mini Chinese Input Method Editor\n",
    "## Discovery and Discussion Notebook\n",
    "I was inspired after reading Peter Norvig's chapter in the book, *Beautiful Data* on Natural Language Corpus Data, and subsequently his [implementation](https://norvig.com/spell-correct.html) of a spelling corrector, and I wondered if I could implement a similar spell corrector for pinyin, with the corrected pinyin being used to suggest individual characters, as a primitive Chinese input method editor would do. The syllable (pinyin without tones) and character frequency lists were taken from [Jun Da](http://lingua.mtsu.edu/chinese-computing/) at Middle Tennessee State University. While I as a linguistics minor, I am interested in natural language processing, but I do not have any significant experience in it besides messing around with NLTK a little bit. I started this project out of curiosity without much expectation, but I figured that nonetheless, it would be an interesting learning experience. I also wanted to use this opportunity to explore how to make Jupyter notebooks more interactive.\n",
    "\n",
    "Intended Organization of the Repository:\n",
    "- Workspace and Discussion Notebook (what you're looking at!): Includes thought process, exploratory visualizations, implementation.\n",
    "- Scripts: Python scripts of the implementation.\n",
    "- Report Notebook: Report outlining the project.\n",
    "- Files: CSV files used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For working with the data\n",
    "import pandas as pd\n",
    "# For the wordcloud\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wordcloud as wc\n",
    "# To get rid of tone marks\n",
    "import unidecode\n",
    "# For interactivity\n",
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "syllables = pd.read_csv(\"C:/Users/rebek/Anaconda3/envs/xiaoshuru/data/syllable frequencies.csv\")\n",
    "characters = pd.read_csv(\"C:/Users/rebek/Anaconda3/envs/xiaoshuru/data/character ranking reduced.csv\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency_rank</th>\n",
       "      <th>character</th>\n",
       "      <th>pinyin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>的</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>一</td>\n",
       "      <td>yī</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>是</td>\n",
       "      <td>shì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>不</td>\n",
       "      <td>bù</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>了</td>\n",
       "      <td>le</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frequency_rank character pinyin\n",
       "0               1         的     de\n",
       "1               2         一     yī\n",
       "2               3         是    shì\n",
       "3               4         不     bù\n",
       "4               5         了     le"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>syllable</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>143836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ai</td>\n",
       "      <td>213586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>an</td>\n",
       "      <td>418511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ang</td>\n",
       "      <td>10267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ao</td>\n",
       "      <td>60455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  syllable  frequency\n",
       "0        a     143836\n",
       "1       ai     213586\n",
       "2       an     418511\n",
       "3      ang      10267\n",
       "4       ao      60455"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From DataFrame to Dictionary\n",
    "In order to work with the data and implement the algorithms, we're going to convert the dataframes into dictionaries.\n",
    "The syllable dictionary is easy, we'll just have the keys be the syllables and the values be the frequencies. This is what we'll use for the spelling corrector, and we can also use it to create the \"wordcloud\" below.\n",
    "\n",
    "The character dictionary is a little more involved, and is what will be used for the IME. It basically *is* the IME, so I'll take the opportunity to explain the intuition behind the IME as we put together the character dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to create simple dictionary from dataframe\n",
    "def simple_dict(df):\n",
    "    # Takes in df, returns first column as keys, second column as values\n",
    "    # Initialize dictionary\n",
    "    simple = dict()\n",
    "    # Iterate through df\n",
    "    for i in range(len(df)):\n",
    "        simple[df.iloc[i, 0]] = df.iloc[i, 1]\n",
    "    # Return dictionary\n",
    "    return simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create syllable dictionary from dataframe, to prep for spelling corrector\n",
    "syll_dict = simple_dict(syllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Wordcloud code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Chinese IMEs don't differentiate between tones, so we won't either. We'll make a new column called \"toneless\" which contains the pinyin without tone marks generated using Unidecode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency_rank</th>\n",
       "      <th>character</th>\n",
       "      <th>pinyin</th>\n",
       "      <th>toneless</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>的</td>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>一</td>\n",
       "      <td>yī</td>\n",
       "      <td>yi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>是</td>\n",
       "      <td>shì</td>\n",
       "      <td>shi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>不</td>\n",
       "      <td>bù</td>\n",
       "      <td>bu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>了</td>\n",
       "      <td>le</td>\n",
       "      <td>le</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frequency_rank character pinyin toneless\n",
       "0               1         的     de       de\n",
       "1               2         一     yī       yi\n",
       "2               3         是    shì      shi\n",
       "3               4         不     bù       bu\n",
       "4               5         了     le       le"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use unidecode to get rid of tone marks, add a new column without tone marks\n",
    "toneless = np.array([])\n",
    "for p in characters[\"pinyin\"]:              \n",
    "    toneless = np.append(toneless, unidecode.unidecode(p))\n",
    "characters[\"toneless\"] = toneless\n",
    "characters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's walk through the intuition behind the IME. Let's say we type in \"yi\" into the IME. Ideally the IME should retrieve all the characters corresponding to \"yi\" in order of usage frequency.\n",
    "\n",
    "Take a look at the dataframe. First, let's get all the rows that have the same toneless pinyin \"yi.\" There are 159 rows, but thankfully, they are already sorted by frequency. But if they weren't, we could just sort them using the Pandas sort() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency_rank</th>\n",
       "      <th>character</th>\n",
       "      <th>pinyin</th>\n",
       "      <th>toneless</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>一</td>\n",
       "      <td>yī</td>\n",
       "      <td>yi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>以</td>\n",
       "      <td>yǐ</td>\n",
       "      <td>yi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2</td>\n",
       "      <td>一</td>\n",
       "      <td>yī</td>\n",
       "      <td>yi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>23</td>\n",
       "      <td>以</td>\n",
       "      <td>yǐ</td>\n",
       "      <td>yi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>104</td>\n",
       "      <td>意</td>\n",
       "      <td>yì</td>\n",
       "      <td>yi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     frequency_rank character pinyin toneless\n",
       "1                 2         一     yī       yi\n",
       "22               23         以     yǐ       yi\n",
       "101               2         一     yī       yi\n",
       "122              23         以     yǐ       yi\n",
       "203             104         意     yì       yi"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yi = characters.loc[characters[\"toneless\"] == \"yi\", :]\n",
    "yi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to save the \"yi\" characters into a list. There are some duplicates, so we'll only save the unique characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yi_characters = list(yi[\"character\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write the function that creates the character dictionary from the character dataframe.\n",
    "\n",
    "For the character dictionary, we're going to have the toneless pinyin as the keys, and the corresponding character lists as the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to create character dictionary from dataframe\n",
    "def character_dict(df):\n",
    "    # Takes in df containing 4 columns: frequency_rank, character, pinyin, toneless\n",
    "    # Returns dictionary with toneless pinyin as the keys, list of corr. characters as values\n",
    "    # Initialize dictionary\n",
    "    chars = dict()\n",
    "    # Get unique list of toneless pinyin\n",
    "    unique_pinyin = df[\"toneless\"].unique()\n",
    "    for u in unique_pinyin:\n",
    "        # Get all rows that have toneless pinyin u\n",
    "        u_rows = df.loc[df[\"toneless\"] == u, :]\n",
    "        # Save u characters into a list, only save the unique characters\n",
    "        u_list = list(u_rows[\"character\"].unique())\n",
    "        # Set u as key, the list as value\n",
    "        chars[u] = u_list\n",
    "    # Return dictionary\n",
    "    return chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the character dictionary!\n",
    "char_dict = character_dict(characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the Pinyin Spelling Corrector for Syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def P(syllable, N=sum(syll_dict.values())): \n",
    "    \"Probability of `syllable`.\"\n",
    "    return syll_dict[syllable] / N\n",
    "\n",
    "def correction(syllable): \n",
    "    \"Most probable spelling correction for syllable.\"\n",
    "    return max(candidates(syllable), key=P)\n",
    "\n",
    "def candidates(syllable): \n",
    "    \"Generate possible spelling corrections for syllable.\"\n",
    "    return (known([syllable]) or known(edits1(syllable)) or known(edits2(syllable)) or [syllable])\n",
    "\n",
    "def known(syllables): \n",
    "    \"The subset of `syllables` that appear in syll_dict.\"\n",
    "    return set(s for s in syllables if s in syll_dict)\n",
    "\n",
    "def edits1(syllable):\n",
    "    \"All edits that are one edit away from `syllable`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(syllable[:i], syllable[i:])    for i in range(len(syllable) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(syllable): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(syllable) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'miao', 'mie'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates(\"mieo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'miao'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction(\"mieo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diu', 'dou', 'du'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates(\"ddu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dou'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction(\"ddu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['描', '妙', '庙', '苗', '秒', '瞄', '渺', '藐', '缈', '喵']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dict[correction(\"mieo\")][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47693fa156d4449baba8257e6ec5fd8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6bc0f35bfd4ca9955311d1ba137d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26d16a3c3a14076a3d8aaa5bdeb07ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "output = widgets.Textarea(description = \"Output: \")\n",
    "pinyin = widgets.Text(description = \"Pinyin Input: \")\n",
    "select = widgets.Select(options=char_dict[correction(\"\")], description = \"Select: \")\n",
    "\n",
    "def pinyin_handler(sender):\n",
    "    select.index = None\n",
    "    select.options = char_dict[correction(pinyin.value)]\n",
    "    output.value = output.value + select.value\n",
    "    # select.observe(on_click, \"value\")\n",
    "    pinyin.value = \"\"\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "def on_click(change):\n",
    "    output.value = output.value[:-1] + select.value\n",
    "    pinyin.index = \"\"\n",
    "\n",
    "\n",
    "\n",
    "display(pinyin)\n",
    "pinyin.on_submit(pinyin_handler)\n",
    "display(select)\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
